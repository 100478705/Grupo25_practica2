{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rodrigo García Salado\n",
    "\n",
    "---\n",
    "### PRÁCTICA 2\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ponemos los imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos el archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el archivo\n",
    "data_df = pd.read_csv(\"Practica2/semillas.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora observamos cuantos y qué tipo de datos vamos a estar tratando\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the data table is:\n",
      "===============================\n",
      "(210, 8)\n",
      "\n",
      "The types of the attributes are:\n",
      "================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 210 entries, 0 to 209\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   area        210 non-null    float64\n",
      " 1   perimetro   210 non-null    float64\n",
      " 2   compacidad  210 non-null    float64\n",
      " 3   longitud    210 non-null    float64\n",
      " 4   anchura     210 non-null    float64\n",
      " 5   asimetria   210 non-null    float64\n",
      " 6   surco       210 non-null    float64\n",
      " 7   clase       210 non-null    int64  \n",
      "dtypes: float64(7), int64(1)\n",
      "memory usage: 13.3 KB\n",
      "\n",
      "How many missing values per attribute:\n",
      "======================================\n",
      "area          0\n",
      "perimetro     0\n",
      "compacidad    0\n",
      "longitud      0\n",
      "anchura       0\n",
      "asimetria     0\n",
      "surco         0\n",
      "clase         0\n",
      "dtype: int64\n",
      "\n",
      "Fraction of missing values per attribute:\n",
      "======================================\n",
      "area          0.0\n",
      "perimetro     0.0\n",
      "compacidad    0.0\n",
      "longitud      0.0\n",
      "anchura       0.0\n",
      "asimetria     0.0\n",
      "surco         0.0\n",
      "clase         0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('The shape of the data table is:')\n",
    "print('===============================')\n",
    "print(data_df.shape)\n",
    "print()\n",
    "\n",
    "print('The types of the attributes are:')\n",
    "print('================================')\n",
    "data_df.info()\n",
    "\n",
    "print()\n",
    "\n",
    "print('How many missing values per attribute:')\n",
    "print('======================================')\n",
    "print(data_df.isnull().sum())\n",
    "\n",
    "print()\n",
    "\n",
    "print('Fraction of missing values per attribute:')\n",
    "print('======================================')\n",
    "print(data_df.isnull().mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEMILLA = 100478705\n",
    "\n",
    "\n",
    "# Separar características y etiquetas\n",
    "X = data_df.drop(columns=['clase']) \n",
    "y = data_df['clase']\n",
    "\n",
    "# Lista de scalers a comparar\n",
    "scalers = {\n",
    "    'StandardScaler': StandardScaler(),\n",
    "    'MinMaxScaler': MinMaxScaler(),\n",
    "    'RobustScaler': RobustScaler()\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creamos la figura para comparar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "StandardScaler\n",
      "Varianza explicada por componente 1: 0.7187\n",
      "Varianza explicada por componente 2: 0.1711\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to numpy.ndarray.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVarianza explicada por componente 1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexplained_var[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVarianza explicada por componente 2: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexplained_var[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVarianza total explicada (2 componentes): \u001b[39m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtotal_explained\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[38;5;124;43m.4f\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Graficar\u001b[39;00m\n\u001b[1;32m     23\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported format string passed to numpy.ndarray.__format__"
     ]
    }
   ],
   "source": [
    "# Iterar sobre los scalers y graficar uno a uno\n",
    "for name, scaler in scalers.items():\n",
    "    # Crear pipeline: scaler + PCA con semilla\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', scaler),\n",
    "        ('pca', PCA(n_components=2, random_state = SEMILLA))\n",
    "    ])\n",
    "\n",
    "    # Transformar los datos\n",
    "    X_pca = pipeline.fit_transform(X)\n",
    "    pca = pipeline.named_steps['pca']  # acceder al PCA para consultar la varianza\n",
    "\n",
    "    # Varianza explicada\n",
    "    explained_var = pca.explained_variance_ratio_\n",
    "    total_explained = np.sum(explained_var)\n",
    "\n",
    "    print(f\"\\n{name}\")\n",
    "    print(f\"Varianza explicada por componente 1: {explained_var[0]:.4f}\")\n",
    "    print(f\"Varianza explicada por componente 2: {explained_var[1]:.4f}\")\n",
    "    print(f\"Varianza total explicada (2 componentes): {total_explained:.4f}\")\n",
    "\n",
    "    # Graficar\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='viridis', edgecolor='k')\n",
    "    plt.title(f'PCA con {name}')\n",
    "    plt.xlabel('PCA 1')\n",
    "    plt.ylabel('PCA 2')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalado con MinMax\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Reducción con PCA a 2 componentes\n",
    "pca = PCA(n_components=2, random_state=SEMILLA)\n",
    "X_pca = pca.fit_transform(X_scaled)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
